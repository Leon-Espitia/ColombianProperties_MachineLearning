{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the train dataset\n",
    "df_train = pd.read_csv(\"./properties_colombia_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand all dataset columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Expand the whole float numbers and leave them all with 2 decimals\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Henry's requirement\n",
    "Priorly, add the 'target' column from the 'price' feature <br>\n",
    "Null values will be replaced by its mean value<br>\n",
    "Then, set it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up categories values as 'expensive' and 'cheap' under the following statement rules\n",
    "price_avg = df_train['price'].mean()\n",
    "df_train['target'] = ['expensive' if price >= price_avg else 'cheap' for price in df_train['price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking dataset after adding the target column\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Switchig to numerical values in the recent column added\n",
    "df_train['target'] = (df_train['target']== 'expensive').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and count 'target' column values \n",
    "df_train.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop 'price' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the 'price' column from df_train dataset\n",
    "df_train= df_train.drop(columns='price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column names\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "Visual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking  numerical column and their metrics\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the dataset general info\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking correlation of price and another numerical columns \n",
    "df_train = df_train[['Unnamed: 0','id', 'ad_type', 'start_date', 'end_date', 'created_on',\n",
    "       'lat', 'lon', 'l1', 'l2', 'l3', 'l4', 'l5', 'l6', 'rooms', 'bedrooms',\n",
    "       'bathrooms', 'surface_total', 'surface_covered', 'currency',\n",
    "       'price_period', 'title', 'description', 'property_type',\n",
    "       'operation_type', 'geometry','target']]\n",
    "                       \n",
    "corr = df_train.corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns,\n",
    "        annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous Person's correlation figure I´ve temporary choosen to keep 'lat', 'lon', 'bathrooms' numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop numerical features from Pearson´s analysis\n",
    "df_train = df_train.drop(columns={'Unnamed: 0','id', 'ad_type', 'start_date', 'end_date', 'created_on',\n",
    "       'rooms', 'bedrooms', 'surface_total', 'surface_covered'})\n",
    "\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After visualization analysis, I´ve decided to drop the following features:<br>\n",
    "a. 'l1' due to the whole properties being located in Colombia.<br>\n",
    "b. 'currency' and 'price_period' because they are irrelevant for properties' price clssification.<br>\n",
    "c. 'title' and 'description' because I won´t implement any \"Natural Language\" Model.<br>\n",
    "d. 'operation_type' all the dataset registers are about properties sale.<br>\n",
    "e. 'geometry' due to I going to use 'lat' and 'lon' features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns irrelevant under my criterion\n",
    "df_train = df_train.drop(columns={'l1', 'currency', 'title', 'price_period', 'description', 'operation_type', 'geometry'})\n",
    "\n",
    "df_train.head(3)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
