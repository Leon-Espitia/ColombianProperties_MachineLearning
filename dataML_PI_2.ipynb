{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the train dataset\n",
    "df_train = pd.read_csv(\"./properties_colombia_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand all dataset columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Expand the whole float numbers and leave them all with 2 decimals\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Henry's requirement\n",
    "Priorly, add the 'target' column from the 'price' feature <br>\n",
    "Null values will be replaced by its mean value<br>\n",
    "Then, set it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up categories values as 'expensive' and 'cheap' under the following statement rules\n",
    "price_avg = df_train['price'].mean()\n",
    "df_train['target'] = ['expensive' if price >= price_avg else 'cheap' for price in df_train['price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking dataset after adding the target column\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Switchig to numerical values in the recent column added\n",
    "df_train['target'] = (df_train['target']== 'expensive').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and count 'target' column values \n",
    "df_train.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop 'price' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the 'price' column from df_train dataset\n",
    "df_train= df_train.drop(columns='price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column names\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "Visual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking  numerical column and their metrics\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the dataset general info\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking correlation of price and another numerical columns \n",
    "df_train = df_train[['Unnamed: 0','id', 'ad_type', 'start_date', 'end_date', 'created_on',\n",
    "       'lat', 'lon', 'l1', 'l2', 'l3', 'l4', 'l5', 'l6', 'rooms', 'bedrooms',\n",
    "       'bathrooms', 'surface_total', 'surface_covered', 'currency',\n",
    "       'price_period', 'title', 'description', 'property_type',\n",
    "       'operation_type', 'geometry','target']]\n",
    "                       \n",
    "corr = df_train.corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns,\n",
    "        annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous Person's correlation figure I´ve temporary choosen to keep 'lat', 'lon', 'bathrooms' numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop numerical features from Pearson´s analysis\n",
    "df_train = df_train.drop(columns={'Unnamed: 0','id', 'ad_type', 'start_date', 'end_date', 'created_on',\n",
    "       'rooms', 'bedrooms', 'surface_total', 'surface_covered'})\n",
    "\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After visualization analysis, I´ve decided to drop the following features:<br>\n",
    "a. 'l1' due to the whole properties being located in Colombia.<br>\n",
    "b. 'currency' and 'price_period' because they are irrelevant for properties' price clssification.<br>\n",
    "c. 'title' and 'description' because I won´t implement any \"Natural Language\" Model.<br>\n",
    "d. 'operation_type' all the dataset registers are about properties sale.<br>\n",
    "e. 'geometry' due to I going to use 'lat' and 'lon' features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns irrelevant under my criterion\n",
    "df_train = df_train.drop(columns={'l1', 'currency', 'title', 'price_period', 'description', 'operation_type', 'geometry'})\n",
    "\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphically visualize missing feature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python library to visualise missing values\n",
    "import missingno as msno\n",
    "\n",
    "msno.bar(df_train, figsize=(10,5), color='lightblue')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values porcentage in 'l4' column\n",
    "(df_train.l4.isnull().sum()/len(df_train)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the previous graphical analysis and supported by the percentage of the missing values decided to drop columns 'l4','l5','l6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "df_train = df_train.drop(columns={'l4', 'l5', 'l6'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features chose to fed the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change feature names\n",
    "df_train = df_train.rename(columns={'l2': 'department',\n",
    "                                    'l3': 'city', \n",
    "                                    'lat': 'latitude',\n",
    "                                    'lon': 'longitude'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking null values\n",
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking graphically\n",
    "msno.bar(df_train, figsize=(8,4), color='pink')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the null numerical feature values with their means\n",
    "df_train['latitude'] = df_train['latitude'].fillna(df_train['latitude'].mean())\n",
    "df_train['longitude'] = df_train['longitude'].fillna(df_train['longitude'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the null 'bathroom' values with their median\n",
    "df_train['bathrooms'] = df_train['bathrooms'].fillna(df_train['bathrooms'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'city' feature has some different column values from the same in the test dataset\n",
    "df_train = df_train.drop('city', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count null values in the whole dataset\n",
    "df_train.isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I´m going to use OneHotEncoder to work with categorical feature values and<br>\n",
    "apply it for each categorical feature in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import encoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "# Applay encoder to the feature\n",
    "codif = ohe.fit_transform(df_train[['department']])\n",
    "\n",
    "# Create a new DF with new values\n",
    "new_cols = pd.DataFrame(codif.toarray(), columns=ohe.categories_[0])\n",
    "\n",
    "# Join dataframes\n",
    "df_train = pd.concat([df_train, new_cols], axis=1)\n",
    "\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply encoder to 'property_type' feature\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "# Applay encoder to the feature\n",
    "codif = ohe.fit_transform(df_train[['property_type']])\n",
    "\n",
    "# Create a new DF with new values\n",
    "new_cols = pd.DataFrame(codif.toarray(), columns=ohe.categories_[0])\n",
    "\n",
    "# Join dataframes\n",
    "df_train = pd.concat([df_train, new_cols], axis=1)\n",
    "\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking dataframe\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'target' feature\n",
    "target = df_train.pop('target')\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete categorical features\n",
    "df_train = df_train.drop(columns=['department', 'property_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign variables to train the ML model\n",
    "X = df_train\n",
    "y = target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I´ve chosen Decision Tree Classifier to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the ML model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=25, random_state=42)\n",
    "clf.fit(X.values, y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model raleted information\n",
    "print(clf.classes_)\n",
    "print(clf.n_classes_)\n",
    "print(clf.max_features_)\n",
    "print(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the model on train dataset values\n",
    "y_pred = clf.predict(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the model efficiency\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cross validation\n",
    "from sklearn.model_selection import cross_validate\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trainig and validation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test the model using the train dataset\n",
    "tree_train_scores_mean = []\n",
    "tree_train_scores_std = []\n",
    "tree_test_scores_mean = []\n",
    "tree_test_scores_std = []\n",
    "\n",
    "depths = np.arange(1,60,1)\n",
    "i = 0\n",
    "i_max = len(depths)\n",
    "for depth in depths:\n",
    "    i = i + 1\n",
    "    clf = DecisionTreeClassifier(max_depth = depth)\n",
    "\n",
    "    # Cross validation on Descicion Tree Classifier\n",
    "\n",
    "    tree_scores = cross_validate(clf, X, y, cv=25, return_train_score=True, n_jobs = -1)\n",
    "    \n",
    "    tree_train_scores_mean.append(tree_scores['train_score'].mean())\n",
    "    tree_train_scores_std.append(tree_scores['train_score'].std())\n",
    "    \n",
    "    tree_test_scores_mean.append(tree_scores['test_score'].mean())\n",
    "    tree_test_scores_std.append(tree_scores['test_score'].std())\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print('Completado: ' + str(round(i / i_max * 100, 2)) + '%')\n",
    "\n",
    "tree_train_scores_mean = np.array(tree_train_scores_mean)\n",
    "tree_train_scores_std = np.array(tree_train_scores_std)\n",
    "tree_test_scores_mean = np.array(tree_test_scores_mean)\n",
    "tree_test_scores_std = np.array(tree_test_scores_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analize the optimal tree depth\n",
    "plt.fill_between(depths, tree_train_scores_mean - tree_train_scores_std,\n",
    "                 tree_train_scores_mean + tree_train_scores_std, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "plt.fill_between(depths, tree_test_scores_mean - tree_test_scores_std,\n",
    "                 tree_test_scores_mean + tree_test_scores_std, alpha=0.1, color=\"g\")\n",
    "\n",
    "plt.plot(depths, tree_train_scores_mean, 'o-', color=\"b\",\n",
    "         label=\"Training score\")\n",
    "plt.plot(depths, tree_test_scores_mean, 'o-', color=\"g\",\n",
    "         label=\"Test score\")\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Descision Tree Classifier depth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the method\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Apply the method\n",
    "confu_matrix = confusion_matrix(y, y_pred)\n",
    "\n",
    "# Evaluation model values\n",
    "confu_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Read the test dataset\n",
    "df_test = pd.read_csv(\"./properties_colombia_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the test dataset\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features from test dataset in the same way of train datast\n",
    "df_test = df_test.drop(columns=['Unnamed: 0', 'id', 'ad_type', 'start_date', 'end_date', 'created_on',\n",
    "        'l1', 'l3', 'l4', 'l5', 'l6', 'rooms', 'bedrooms', 'surface_total', 'surface_covered', 'currency',\n",
    "       'price_period', 'title', 'description',\n",
    "       'operation_type', 'geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the null numerical feature values with their means\n",
    "df_test['lat'] = df_test['lat'].fillna(df_test['lat'].mean())\n",
    "df_test['lon'] = df_test['lon'].fillna(df_test['lon'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the null 'bathroom' values with their median\n",
    "df_test['bathrooms'] = df_test['bathrooms'].fillna(df_test['bathrooms'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking null values\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for the same amount of columns as the train dataset\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneHotEcoder\n",
    "Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import encoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "# Apply encoder to the dataset feature\n",
    "codif = ohe.fit_transform(df_test[['l2']])\n",
    "\n",
    "# Create a new DF with new values\n",
    "new_cols = pd.DataFrame(codif.toarray(), columns=ohe.categories_[0])\n",
    "\n",
    "# Conactenate dataframes\n",
    "df_test = pd.concat([df_test, new_cols], axis=1)\n",
    "\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applay encoder to the dataset feature\n",
    "codif = ohe.fit_transform(df_test[['property_type']])\n",
    "\n",
    "# Create a new DF with new values\n",
    "new_cols = pd.DataFrame(codif.toarray(), columns=ohe.categories_[0])\n",
    "\n",
    "# Join dataframes\n",
    "df_test = pd.concat([df_test, new_cols], axis=1)\n",
    "\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete categorical features\n",
    "df_test = df_test.drop(columns=['l2', 'property_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for the same amount of columns as the train dataset in the final test dataset\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the test dataset to make predictions by applying the ML model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#clf = DecisionTreeClassifier(max_depth=25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "X_test_predict = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the trained ML model to the modified test dataset\n",
    "y_test_predict = clf.predict(X_test_predict.values)\n",
    "\n",
    "# Checking predictions\n",
    "y_test_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Henry's final task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions dataset\n",
    "pred = pd.DataFrame(y_test_predict, columns=['pred'])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, save the prediction dataset as a .csv file.\n",
    "pred.to_csv('Leon-Espitia.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
